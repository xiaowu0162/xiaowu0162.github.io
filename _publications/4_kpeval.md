---
title: "KPEval: Towards Fine-grained Semantic-based Evaluation of Keyphrase Extraction and Generation Systems"
collection: publications
Authors: ' <b>Di Wu</b>, Da Yin, and Kai-Wei Chang.'
date: 03/2023
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2303.15422'
codeurl: 'https://github.com/uclanlp/KPEval'
excerpt: ''
---
---
<a href='https://arxiv.org/pdf/2303.15422.pdf' target="_blank">[Download Paper]</a><a href='https://github.com/uclanlp/KPEval' target="_blank">[Source Code]</a>

<p align="justify">
Despite the significant advancements in keyphrase extraction and keyphrase generation methods, the predominant approach for evaluation only relies on exact matching with human references and disregards reference-free attributes. This scheme fails to recognize systems that generate keyphrases that are semantically equivalent to the references or keyphrases that have practical utility. To better understand the strengths and weaknesses of different keyphrase systems, we propose a comprehensive evaluation framework consisting of six critical dimensions: naturalness, faithfulness, saliency, coverage, diversity, and utility. For each dimension, we discuss the desiderata and design semantic-based metrics that align with the evaluation objectives. Rigorous meta-evaluation studies demonstrate that our evaluation strategy correlates better with human preferences compared to a range of previously used metrics. Using this framework, we re-evaluate 18 keyphrase systems and further discover that (1) the best model differs in different dimensions, with pre-trained language models achieving the best in most dimensions; (2) the utility in downstream tasks does not always correlate well with reference-based metrics; and (3) large language models exhibit a strong performance in reference-free evaluation.
</p>
